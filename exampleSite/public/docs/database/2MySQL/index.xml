<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Cookbook School Recruitment</title>
    <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/</link>
    <description>Recent content on Computer Cookbook School Recruitment</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://books.grayson.top/school-recruitment/docs/database/2MySQL/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.1-%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.1-%E7%B4%A2%E5%BC%95/</guid>
      <description>索引 #  1 含义 #   索引是存储数据库表中的一列或多列的值并对其进行排序的一种数据结构，他通过缩小一张表中需要查询的记录的数目来加快搜索的速度，如果没有索引，数据库将不得不进行全表扫描。 索引相当于图书中的目录，可以根据目录上的页码快速找到所需的内容，提高查询速度。  2 优缺点 #  2.1 优点 #   通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度，避免进行全表的数据扫描，大大减少遍历匹配的行数，这也是创建索引的最主要的原因。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。  2.2 缺点 #   创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占用物理空间，数据量越大，占用空间越大。 会降低表的增删改的效率，因为每次增删改索引，都需要进行动态维护。  3 在哪些列建立索引 #   在经常需要搜索的列上，可以加快搜索的速度。 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构。 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度。 在经常需要根据范围进行搜索的列上，因为索引已经排序，其指定的范围是连续的。 在经常需要排序的列上，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。 在经常使用在 where 子句的列上，因为这样可以加快条件的判断速度。 在经常需要统计或分组的列上。  4 不在哪些列创建索引 #   对于那些在查询中很少使用的列不应该创建索引，因为既然这些列很少使用到，因此有索引或者无索引并不能提高查询速度，相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些只有很少取值的列也不应该创建索引，因为由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大，增加索引并不能明显加快检索速度。 对于那些定义为 text、image、bit 数据类型的列不应该创建索引，因为这些列的数据量要么相当大，要么取值很少。 当修改性能远远大于检索性能时，不应该创建索引，因为修改性能和检索性能是互相矛盾的，当增加索引时，会提高检索性能，但是会降低修改性能，当减少索引时，会提高修改性能，但是会降低检索性能。  5 什么情况下索引会失效 #    在 where 子句中进行 null 值判断：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.2-B-%E6%A0%91B&#43;%E6%A0%91%E7%B4%A2%E5%BC%95%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.2-B-%E6%A0%91B&#43;%E6%A0%91%E7%B4%A2%E5%BC%95%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</guid>
      <description>B 树、B+树索引算法原理 #  1 为什么要用 B 树、B+ 树索引 #    常用的数据结构如二叉查找树（Binary Search Tree, BST）的每个节点只能容纳一个数据，导致树的高度很高，逻辑上挨着的节点的数据可能离得很远，如果在内存中操作数据的话，这样问题并不大，但是由于读写磁盘的速度相比内存慢很多，每次读写磁盘的单位要比读写内存的最小单位大很多。
  因此，对应的数据结构应该尽量的满足局部性原理，即当一个数据被用到时，其附近的数据也通常会马上被使用，因此，逻辑上相邻的数据在物理上也尽量存储在一起，这样才能减少读写磁盘的数量。
  因此，对比起一个节点只能存储一个数据的 BST 类数据结构来说，要求这种数据结构在形状上更胖，更加扁平，即每个节点能容纳更多的数据，这样就能降低树的高度，同时让相邻的数据都能尽量的存储在物理上也相邻的硬盘空间上，减少磁盘读写。
  以下图为例，图中从根节点出发，查找数据 14 的过程中，经过的第二节点中有键值 [3,7,13]，这三个值在逻辑上是相邻的，如果他们在磁盘上的存储也能做到在物理上相邻，那么只需要一次读操作就能把这个节点的数据从磁盘上加载到内存中进行数据比较，这样整个过程就只需要两次磁盘读操作，这种数据结构具有两个特点：
 高扇出： 临近键值的数据局部性更好。 低高度： 遍历期间的寻道次数更少。     B 树和 B+ 树就是两种利用磁盘局部性原理进行优化的树结构。
  2 B 树 #  2.1 B 树的定义及性质 #    在 B 树种，分为两种节点：
 内部节点（Internal Node）： 存储了数据以及指向其子节点的指针。 叶子节点（Leaf Node）： 叶子节点只存储数据，没有子节点。    一个数据，既可能存在内部节点上，也可能存在叶子节点上，这一点是与 B+ 树最大的不同，B+ 树只会将数据存储在叶子节点上。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.3-%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E8%A1%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.3-%E7%B4%A2%E5%BC%95%E7%BB%84%E7%BB%87%E8%A1%A8/</guid>
      <description>索引组织表 #   在InnoDB存储引擎中，表都是按照主键顺序组织存放的，这种存储方式的表称为索引组织表（Index Organzied Table）。 在InnoDB存储引擎中，每张表都有个主键（Primary Key），如果在创建表时没有显式地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键：  首先判断表中是否有非空的唯一索引（Unique NOT NULL），如果有，该列即为主键，当表中有多个非空唯一索引时，InnoDB存储引擎将选择建表时第一个定义的非空唯一索引为主键，这里需要注意的是，主键的选择根据的是定义索引的顺序，而不是建表时列的顺序，例如下面的例子：   建表及插入数据语句为：
create table z( a int not null, b int null, c int not null, d int not null, unique key(b), unique key(d), unique key(c) ) engine=innodb; insert into z select 1,2,3,4; insert into z select 5,6,7,8; insert into z select 9,10,11,12;   上面示例中创建了一张表 z，有 a、b、c、d四列，b、c、d三列都有唯一索引，不同的是 b列允许NULL值，由于没有显式地定义主键，因此会选择非空的唯一索引，虽然 c、d列都是非空唯一索引，都可以作为主键的候选，但是在定义的过程中，由于 d列首先定义为唯一索引，因此InnoDB存储引擎将 d列视为主键。
  可以通过下面的SQL语句判断表的主键值，其中 _rowid可以显示表的主键，但是只能用于查看单个列作为主键的情况，不能用于多列组成主键的情况。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.4-InnoDB%E5%92%8CMyISAM%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.4-InnoDB%E5%92%8CMyISAM%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>InnoDB和MyISAM的区别 #  存储引擎主要用于从数据库中读取数据，MySQL 支持很多 存储引擎，但是 MyISAM 和 InnoDB 是使用最广泛的两个存储引擎，他们每一个都有各自的优缺点，因此选取一个适合我们应用的存储引擎来说非常重要。
 MySQL 5.5.5 之前的版本的默认存储引擎是 MyISAM，5.5.5 及其之后的版本的默认存储引擎是 InnoDB。
 MyISAM 和 InnoDB 的主要区别包括参照完整性（Referential Integrity）、事务和原子性（Transactions &amp;amp; Atomicity）、表锁定与行锁定（Table-locking vs Row-locking）、可靠性（Reliability）、全文索引（FULLTEXT Indexing）、缓存（Caching）、ACID 属性（ACID property）七个方面。
1 参照完整性 #   参照完整性确保了表与表之间的关系的一致性，比如一张表拥有指向另外一张表的外键，当被指向的表发生更改时，这些更改也会级联到链接表。 InnoDB 是一个关系型数据库管理系统（RDBMS），因此InnoDB 支持外键和参照完整性，包括级联删除和更新，但是MyISAM 不支持外键。  2 事务和原子性 #   MyISAM 不支持事务，但是InnoDB 支持。 因此，当一张表使用 MyISAM 引擎并且操作在执行的过程中被终止了，已经被更改的行将会被永久更改，即使操作还没有完成，但是当一张表是使用 InnoDB 引擎并且操作在执行的过程中被终止了，因为使用了事务，因此当我们提交之前，所有的更改将不会生效。 当我们使用 MyISAM 引擎时，所有的更改不能回滚，但是当我们使用 InnoDB 引擎时，更改是可以被回滚的。  3 表锁定和行锁定 #   当在MyISAM 引擎的表中执行一个查询时，整张表都会被锁定，这意味着后续查询只能等到当前查询结束之后才会被执行，当我们正在读一张大表时，而且同时这张表会有其他频繁的读写操作，这可能导致大量的查询被积压。 当在InnoDB 引擎的表中执行一个查询时，只有相关的行才会被锁定，表中的其他行可以继续进行其他操作，这意味着当查询不使用同一行时，可以在一个表上同时运行。  4 可靠性 #   MyISAM 引擎不提供数据完整性，比如硬件损坏（Hardware Failures）、突然关机（Unclean Shutdowns）或者操作取消（Canceled Operations）都会导致数据损坏，这就需要对表进行完全修复或者重建索引和表。 InnoDB 引擎使用事务日志（Transactional Log）、双写缓冲区（Double-Write Buffer）以及自动校验和验证（Automatic Checksum and Validation）来防止数据损坏，当 InnoDB对数据进行更改之前，他会在事务之前把数据记录到一个名为 ibdata1 的系统表空间文件（System Tablespace File），如果 MySQL 服务器发生崩溃，InnoDB 将会根据这些日志来自动恢复数据。  5 全文索引 #   在 MySQL 5.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.5-Checkpoint%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.5-Checkpoint%E6%8A%80%E6%9C%AF/</guid>
      <description>Checkpoint技术 #  1 前言 #   缓冲池设计的目的是为了协调 CPU 速度与磁盘速度的鸿沟，因此页的操作首先都是在缓冲池中完成的。 如果一条DML 语句，如UPDATE 或DELETE改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新，数据库需要将新版本的页从缓冲池刷新到磁盘。 倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的，若热点数据集中在某几个页中，那么数据库的性能将变得非常差，同时，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。 为了避免发生数据丢失的问题，当前事务数据库系统普遍都采用了WAL（Write Ahead Log）策略，即当事务提交时，先写 重做日志（Redo Log），再修改页，当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复，这也是 事务 ACID中 D（Durability，持久性）的要求。  2 为什么需要 Checkpoint 技术 #   思考下面的场景，如果重做日志可以无限的做大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池页的新版本刷新回磁盘，因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生的时刻，但是这需要两个前提条件：  缓冲池可以缓存数据库中所有的数据。  有经验的用户都知道，当数据库开始建的时候，表中没有任何数据，缓冲池的确可以缓存所有的数据库文件。 然而随着市场的推广，用户的增加，产品越来越受到关注，使用量也越来越大，这时负责后台存储的数据库的容量注定会不断增大。 当前3TB的MySQL数据库已并不少见，但是3TB的内存却非常少见，因此这一假设对于生产环境应用中的数据库是很难得到保证的。   重做日志可以无限增大。  这个也许是可以的，但是对成本要求太高，同时不便于运维，因为我们不知道什么时候重做日志是否已接近于磁盘可使用空间的阈值，并且要让存储设备支持可动态扩展也是需要一定的技巧和设备支持的。     即使上面两个条件都满足，那么还有一个条件需要考虑，那就是宕机后数据库的恢复时间，当数据库运行了几个月甚至几年时，这时发生宕机，重新应用重做日志的时间会非常久，此时恢复的代价也会非常大，此时，就需要使用Checkpoint（检查点）技术了。  3 解决的主要问题 #  Checkpoint技术的目的是解决以下几个问题：
 缩短数据库的恢复时间。  当数据库发生宕机时，数据库不需要重做所有的日志，因为Checkpoint之前的页都已经刷新回磁盘，故数据库只需对Checkpoint后的重做日志进行恢复，这样就大大缩短了恢复的时间。   缓冲池不够用时，将脏页刷新到磁盘。  当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页也就是页的新版本刷回磁盘。   重做日志不可用时，刷新脏页。  重做日志不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，这从成本及管理上都是比较困难的。 重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。 若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲池中的页至少刷新到当前重做日志的位置。    4 分类 #  在InnoDB存储引擎中，Checkpoint发生的时间、条件及脏页的选择等都非常复杂，而Checkpoint所做的事情无外乎是将缓冲池中的脏页刷回到磁盘，不同之处在于每次刷新多少页到磁盘，每次从哪里取脏页，以及什么时间触发Checkpoint，在InnoDB引擎内部，有两种Checkpoint，分别为Sharp Checkpoint、Fuzzy Checkpoint。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.6-%E5%AE%95%E6%9C%BA%E6%81%A2%E5%A4%8D%E5%8E%9F%E7%90%86/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.6-%E5%AE%95%E6%9C%BA%E6%81%A2%E5%A4%8D%E5%8E%9F%E7%90%86/</guid>
      <description>宕机恢复原理 #  1 前言 #  MySQL 保证数据不丢失的能力主要体现在两个方面：
 能够恢复到任何时间点的状态。  对于这一点，只要保留足够的 Binlog，就可以通过重跑 Binlog 来实现。   能够保证 MySQL 在任何时间段突然崩溃，重启之后之前提交的记录都不会丢失。  对于这一点，也就是本文所说的宕机恢复，即在 InnoDB 存储引擎中，事务提交过程中任何阶段，MySQL 突然崩溃，重启后都能保证事务的完整性，已提交的事务不会丢失，未提交完整的数据会自动进行回滚，这个能力依赖的就是 Redo Log和 Undo Log两个日志。 因为宕机恢复主要体现在事务执行过程中突然崩溃，重启后能保证事务的完整性，所以在讲解具体的原理前，先了解一下 MySQL 事务执行有哪些关键阶段，后面才能依据这几个阶段来进行解析，下面以一条更新语句的执行流程为例来进行说明：  从内存中找出这条数据记录，对其进行更新。 将旧数据记录到 Undo Log 中。 将对数据页的更改记录到 Redo Log Buffer 中，状态为prepare 状态。 将逻辑操作记录到 Binlog Cache 中。 将 Redo Log 中的更改记录设置为commit 状态。  对于内存中的数据和日志，都是由后台线程来进行处理，当触发到落盘规则后再异步进行刷盘。
       2 WAL 技术 #   MySQL更改数据的时候，不是直接写磁盘文件中的数据，因为直接写磁盘文件是随机写，开销大性能低，没办法满足 MySQL 的性能要求，因此会设计成先在内存中对数据进行更改，再异步落盘。 但是内存总是不可靠，万一断电重启，还没来得及落盘的内存数据就会丢失，所以还需要加上写日志这个步骤，万一断电重启，还能通过日志中的记录进行恢复。 写日志虽然也是写磁盘，但是他是顺序写，相比随机写开销更小，能提升语句的执行性能。 这个技术就是大多数存储系统都会用的WAL（Write Ahead Log）技术，也称为日志先行的技术，指的是对数据文件进行修改前，必须将修改先记录日志，这样可以保证数据的一致性和持久性，也能提升语句执行性能。  3 核心日志模块 #  更新 SQL 执行过程中，总共涉及 MySQL 日志模块其中的三个核心日志，分别是 Redo Log（重做日志）、Undo Log（回滚日志）、Binlog（归档日志），下面将会对的三个日志进行一个概要介绍，详细的内容可以参考 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.7-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.7-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/</guid>
      <description>数据库优化 #  1 SQL 语句的优化 #   优化 SQL 语句时可以按照以下的步骤来进行：
 首先分析慢查询日志，这里面记录了响应时间超过阈值 long_query_time 的 SQL 语句，通过日志找出 IO 大的 SQL 以及发现未命中索引的 SQL。 然后使用 EXPLAIN 对慢查询 SQL 进行分析，通过EXPLAIN 命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、哪些索引被实际使用、表之间的引用以及被扫描的行数等问题。     应尽量避免在 WHERE 子句中使用 !=、&amp;lt;、&amp;gt;操作符或对字段进行 null 值判断，否则数据库引擎将放弃使用索引而进行全表扫描。
  只返回必要的列，最好不要用 SELECT * 语句。
  只返回必要的行，使用 LIMIT 语句来限制返回的数据。
  高并发高性能的应用中尽量对关联查询分解为单表查询，然后将结果在应用程序中进行关联，例如下面这个查询：
select * from tag join tag_post on tag_post.tag_id=tag.id join post on tag_post.post_id=post.id where tag.tag=&amp;#39;mysql&amp;#39;; 可以分解成下面这些查询来代替：
select * from tag where tag=&amp;#39;mysql&amp;#39;; select * from tag_post where tag_id=1234; select * from post where id in(123,456,567,9989,8909); 这种用分解关联查询的方式重构查询具有如下优势：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.8-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.8-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</guid>
      <description>分库分表 #  1 为什么要进行分库分表 #    在业务数据量比较少的时代，我们使用单机数据库就能满足业务使用，随着业务请求量越来越多，数据库中的数据量快速增加，这时单机数据库已经不能满足业务的性能要求，数据库主从架构随之应运而生。
  主从复制是将数据库写操作和读操作进行分离，使用多个只读实例（Slaver Replication）负责处理读请求，主实例（Master）负责处理写请求，只读实例通过复制主实例的数据来保持与主实例的数据一致性，由于只读实例可以水平扩展，所以更多的读请求不成问题。
  随着云计算、大数据时代的到来，事情并没有完美的得以解决，当写请求越来越多，主实例的写请求变成主要的性能瓶颈。
  如果仅仅通过增加一个主实例来分担写请求，写操作如何在两个主实例之间同步来保证数据一致性，如何避免双写，此时问题会变得更加复杂，这时就需要用到分库分表（Sharding），对写操作进行切分来解决，如下图所示：
  上图中的 DDM 为华为云的中间件产品，全称是 Distributed Database Middleware，作为 RDS（Relational Database Service）的前置分布式数据库访问服务，彻底解决了数据库的扩展性问题，对应用透明地实现海量数据的高并发访问，实现了读写分离和分库分表。
   2 分库分表的切分方式 #   数据的切分（Sharding）根据其切分规则的类型，可以分为两种切分模式：  一种是按照不同的表（或者 Schema）来切分到不同的数据库（主机）上，这种切分方式可以称之为数据的垂直（纵向）切分。 另外一种则是根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。   垂直切分最大的特点就是规则简单，实施也更为方便，尤其适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统，在这种系统中，可以很容易做到将不同业务模块所使用的的表拆分到不同的数据库中，根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰。 水平切分相对于垂直切分来说，稍微复杂一些，因为要将同一个表中的不同数据拆分到不同的数据库中，对于应用程序来说，拆分规则本身比根据表名来拆分更为复杂，后期的数据维护也会更为复杂一些。 具体而言，如果单个库太大，这是我们要看是因为表多而导致数据多，还是因为单张表里面的数据多：  如果是因为表多而数据多，则使用垂直切分，根据业务切分成不同的库。 如果是因为单张表的数据量太大，这时要用水平切分，即把表的数据按照某种规则切分成多张表，甚至多个库上的多张表。   分库分表的顺序应该是先垂直分，后水平分，因为垂直分更简单，更符合我们处理现实世界问题的方式。  3 垂直切分 #  3.1 含义 #    垂直切分常见有垂直分库和垂直分表两种。
  垂直分库就是根据业务耦合性，将关联度低的表存储在不同的数据库，做法与大系统拆分为多个小系统类似，按业务分类进行独立划分：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.9-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.9-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</guid>
      <description>一致性哈希算法 #  1 传统哈希算法 #  1.1 含义 #   简单地说，哈希就是一个键值对存储，在给定键的情况下，可以非常高效地找到所关联的值，假如我们要根据邮政编码查找城市中的街道名称，一种最简单的实现方式是将此信息以哈希字典的形式进行存储&amp;lt;ZipCode, StreetName&amp;gt;。 当数据太大而无法存储在一个节点或机器上时，系统就会需要多个这样的节点或机器来存储他，比如，使用多个 Web 缓存中间件的系统，对于如何确定哪个key 存储在哪个节点上，最简单的解决方案是使用哈希取模来决定：   给定一个 key，先对 key 进行哈希运算，将其除以系统中的节点数，然后将 key 放入该节点。
  在获取 key 时，先对 key 进行哈希运算，将其除以系统中的节点数，然后转到该节点并获取值。
  上述过程对应的哈希算法定义如下：
# 下面的 N 为节点数 node_number = hash(key) % N   下图描绘了多节点系统中的传统的哈希取模算法，基于该算法可以实现简单的负载均衡。
     1.2 局限性 #  假设初始时有如下对应关系：
 1.2.1 节点减少的场景 #   在分布式多节点系统中，出现故障很常见，任何节点都可能在没有任何事先通知的情况下挂掉，针对这种情况，我们希望系统只是出现性能降低，正常的功能不会受到影响。 对于原始示例，假设其中 1 个节点出现了故障，这时节点数发生了变化，节点个数从 3 减少为 2，此时表格中的状态发生了变化：  很明显节点的减少会导致键与节点的映射关系发生变化，这个变化对于新的键来说并不会产生任何影响，但对于已有的键来说，将会导致节点映射错误，以semlinker 为例，变化前系统有 3 个节点，该键对应的节点编号为 1，当出现故障时，节点数减少为 2 个，此时该键对应的节点编号为 0。  1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.10-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://books.grayson.top/school-recruitment/docs/database/2MySQL/2.10-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</guid>
      <description>主从复制 #  1 什么是主从复制 #   MySQL 主从复制是指数据可以从一个 MySQL 数据库服务器主节点复制到一个或多个从节点。 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。  2 为什么要主从复制 #   读写分离：  在开发工作中，有时候会遇见某个 SQL 语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务。 使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。   数据实时备份：  当系统中某个节点发生故障时，可以方便的故障切换。   高可用 HA。 架构扩展：  随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O 访问频率过高。 有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘 I/O 访问的频率，提高单个机器的 I/O 性能。    3 常见架构模型 #  3.1 一主一从/一主多从 #   一主一从和一主多从是最常见的主从架构模式，一般实现主从配置或者读写分离都可以采用这种架构。 如果是一主多从模式，当b增加到一定数量时，Slave 对 Master 的负载以及网络带宽都会成为一个严重的问题。   3.2 多主一从 #   MySQL 5.7 开始支持多主一从的模式，将多个库的数据备份到一个库中存储。   3.</description>
    </item>
    
  </channel>
</rss>
